{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quick Prediction Test\n",
    "\n",
    "Simple notebook to test the transformer model on custom text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.insert(0, str(Path.cwd().parent))\n",
    "\n",
    "import torch\n",
    "from transformers import DistilBertModel, DistilBertTokenizerFast\n",
    "import transformer.config as config\n",
    "from transformer.model import TransformerClassifier, DebiasedTransformerClassifier\n",
    "\n",
    "# Load model\n",
    "ensemble_info = torch.load(config.CACHE_DIR / 'transformer_ensemble_info.pt', weights_only=True)\n",
    "best_fold = ensemble_info['top_indices'][-1]\n",
    "checkpoint = torch.load(config.CACHE_DIR / f'transformer_model_fold_{best_fold}.pt', weights_only=True)\n",
    "\n",
    "bert = DistilBertModel.from_pretrained(config.TRANSFORMER_MODEL)\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained(config.TRANSFORMER_MODEL)\n",
    "\n",
    "# Load correct model type\n",
    "is_debiased = checkpoint.get('debiased', False)\n",
    "print(f'Model type: {\"Debiased\" if is_debiased else \"Standard\"}')\n",
    "\n",
    "if is_debiased:\n",
    "    model = DebiasedTransformerClassifier(\n",
    "        input_dim=768, hidden_dim=256, dropout=0.5,\n",
    "        num_extra_features=checkpoint.get('num_extra_features', 0),\n",
    "        gradient_reversal_lambda=config.GRADIENT_REVERSAL_LAMBDA\n",
    "    )\n",
    "else:\n",
    "    model = TransformerClassifier(\n",
    "        input_dim=768, hidden_dim=256, dropout=0.5,\n",
    "        num_extra_features=checkpoint.get('num_extra_features', 0)\n",
    "    )\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.eval()\n",
    "bert.eval()\n",
    "\n",
    "print(f'Loaded fold {best_fold} (F1={ensemble_info[\"fold_scores\"][best_fold]:.4f})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(text):\n",
    "    encoding = tokenizer(text, return_tensors='pt', truncation=True, max_length=512, padding=True)\n",
    "    with torch.no_grad():\n",
    "        outputs = bert(**encoding)\n",
    "        cls_embedding = outputs.last_hidden_state[:, 0]\n",
    "        prob = model(cls_embedding).item()\n",
    "    label = 'HYPERPARTISAN' if prob > 0.5 else 'MAINSTREAM'\n",
    "    return prob, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test your article here\n",
    "article = \"\"\"The corrupt politicians are destroying our country with their radical socialist agenda.\"\"\"\n",
    "\n",
    "prob, label = predict(article)\n",
    "print(f'P(hyperpartisan): {prob:.3f}')\n",
    "print(f'Prediction: {label}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# More examples\n",
    "examples = [\n",
    "    \"Trump is destroying America with his fascist policies.\",\n",
    "    \"The president signed the bill into law on Tuesday.\",\n",
    "    \"Democrats are evil communists trying to take our freedom.\",\n",
    "    \"Congress passed bipartisan legislation on infrastructure spending.\",\n",
    "]\n",
    "\n",
    "for text in examples:\n",
    "    prob, label = predict(text)\n",
    "    print(f'{label:12} ({prob:.2f}): {text[:60]}...')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
